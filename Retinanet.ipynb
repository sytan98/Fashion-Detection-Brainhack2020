{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"Retinanet.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"6taoHX1zomlw","colab_type":"text"},"source":["# Information about Notebook\n","- Referenced https://github.com/fizyr/keras-retinanet.git\n","- Google Images v6 images used in conjunction with the dataset provided"]},{"cell_type":"markdown","metadata":{"id":"bTi3vTr1ofOC","colab_type":"text"},"source":["# Environment Set Up"]},{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"SU3SN-MhofOD","colab_type":"code","colab":{}},"source":["!git clone https://github.com/fizyr/keras-retinanet.git\n","\n","%cd keras-retinanet/\n","!pip install .\n","\n","!python setup.py build_ext --inplace"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"ENgvmU2XofOG","colab_type":"code","colab":{}},"source":["import os\n","import shutil\n","import zipfile\n","import urllib\n","import xml.etree.ElementTree as ET\n","import numpy as np\n","import csv\n","import math\n","import pandas\n","import json\n","import cv2\n","import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"viPHbCGtofOJ","colab_type":"code","colab":{}},"source":["annotations = []\n","valannotations = []\n","classes = ['tops','trousers','outerwear','dresses','skirts']\n","\n","for i, line in enumerate(classes):\n","    print('{},{}'.format(line,i))\n","\n","#FOR ANNOTATIONS\n","with open('/kaggle/input/tildata-combined1/train_combined_cleaned.json', mode='r') as json_file:\n","    data = json.load(json_file)\n","    for row in data:\n","        left,top,width,height = row['bbox']\n","        item = ['/kaggle/input/tildata-combined1/train_combined/train_combined/'+str(row['image_id'])+'.jpg'] + [left, top, left+width, top+height] + [classes[row['category_id'] - 1]]\n","        annotations.append(item)\n","\n","#FOR VALIDATION ANNOTATIONS\n","with open('/kaggle/input/retinanetcsvfiles/validation.csv', mode='r') as csv_file:\n","    csv_reader = csv.DictReader(csv_file)\n","    line_count = 0\n","    for row in csv_reader:\n","        if line_count == 0:\n","            print(f'Column names are {\", \".join(row)}')\n","            line_count += 1\n","        item = ['/kaggle/input/til2020/'+row['filename']] + [math.floor(float(row['xmin'])),math.floor(float(row['ymin'])),math.floor(float(row['xmax'])),math.floor(float(row['ymax']))] + [row['class']]\n","        valannotations.append(item)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"TzmApzI9ofOL","colab_type":"code","colab":{}},"source":["ANNOTATIONS_FILE = '/kaggle/working/annotations.csv'\n","VALANNOTATIONS_FILE = '/kaggle/working/valannotations.csv'\n","CLASSES_FILE = '/kaggle/working/classes.csv'\n","\n","with open(ANNOTATIONS_FILE, 'w') as f:\n","  writer = csv.writer(f)\n","  writer.writerows(annotations)\n","\n","with open(CLASSES_FILE, 'w') as f:\n","  writer = csv.writer(f)\n","  for i, line in enumerate(classes):\n","    f.write('{},{}\\n'.format(line,i))\n","  \n","with open(VALANNOTATIONS_FILE, 'w') as f:\n","  writer = csv.writer(f)\n","  writer.writerows(valannotations)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1TsHWUfqofON","colab_type":"text"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"gUkuIsEqpfrR","colab_type":"code","colab":{}},"source":["PRETRAINED_MODEL = './snapshots/resnet101_pretrained_model.h5'\n","\n","DOWNLOAD INITIAL PRETRAINED MODEL FROM FIZYR\n","URL_MODEL = 'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet101_oid_v1.0.0.h5'\n","\n","urllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)\n","\n","print('Downloaded pretrained model to ' + PRETRAINED_MODEL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"fruzE1PwofON","colab_type":"code","colab":{}},"source":["TRAIN = \"./keras_retinanet/bin/train.py\"\n","\n","#PRETRAINED_MODEL = './snapshots/resnet101_pretrained_model.h5'\n","SNAPSHOT1 = \"../../input/retinanet-trained-models/resnet101combined10epochs_snapshot.h5\"\n","\n","VALANNOTATIONS = \"../valannotations.csv\"\n","ANNOTATIONS = \"../annotations.csv\" \n","CLASSES = \"../classes.csv\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"uxVvXqb9ofOP","colab_type":"code","colab":{}},"source":["!python {TRAIN}  --snapshot {SNAPSHOT1} --backbone {'resnet101'} --image-min-side 400 --image-max-side 700 --freeze-backbone --random-transform --batch-size 8 --steps 500 --epochs 5 csv {ANNOTATIONS} {CLASSES}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ipkkSyQxofOR","colab_type":"text"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"sZr4LbPZofOS","colab_type":"text"},"source":["Convert training model to inference model"]},{"cell_type":"code","metadata":{"trusted":true,"id":"7N-pzaI0ofOS","colab_type":"code","colab":{}},"source":["#change the file paths of the snapshot and where to save the inference model to\n","model_path = os.path.join('snapshots', sorted(os.listdir('snapshots'), reverse=True)[1])\n","print(model_path)\n","\n","CONVERT = './keras_retinanet/bin/convert_model.py'\n","SNAPSHOT2 = model_path\n","INFERENCEMODEL = './snapshots/output.h5'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"j1o360Z6ofOU","colab_type":"code","colab":{}},"source":["!python './keras_retinanet/bin/convert_model.py' {model_path} './snapshots/output.h5'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6TYkxAwNofOW","colab_type":"text"},"source":["Evauation using built-in mAP"]},{"cell_type":"code","metadata":{"trusted":true,"id":"uetk-k2KofOX","colab_type":"code","colab":{}},"source":["EVALUATE = './keras_retinanet/bin/evaluate.py'\n","\n","INFERENCEMODEL = './snapshots/output.h5'\n","\n","VALANNOTATIONS = \"../valannotations.csv\"\n","ANNOTATIONS = \"../annotations.csv\" \n","CLASSES = \"../classes.csv\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"rY3IaTJLofOZ","colab_type":"code","colab":{}},"source":["!python {EVALUATE} --iou-threshold 0.5 --max-detections 100 csv {VALANNOTATIONS} {CLASSES} {INFERENCEMODEL}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s1S_VOmbofOa","colab_type":"text"},"source":["Evaluation using COCOapi"]},{"cell_type":"code","metadata":{"trusted":true,"id":"FknBdmLuofOb","colab_type":"code","colab":{}},"source":["os.getcwd()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"e2ZeD0NEofOd","colab_type":"code","colab":{}},"source":["from keras_retinanet.models import load_model\n","model = load_model('snapshots/output.h5', backbone_name='resnet101')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"dat4sVULofOe","colab_type":"code","colab":{}},"source":["%cd '/kaggle/working/keras-retinanet'\n","\n","# import keras\n","import keras\n","\n","# import keras_retinanet\n","from keras_retinanet import models\n","from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n","from keras_retinanet.utils.visualization import draw_box, draw_caption\n","from keras_retinanet.utils.colors import label_color"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"yV8ueB3bofOg","colab_type":"code","colab":{}},"source":["detections = []\n","score_threshold = 0.\n","\n","for root, dirs, files in os.walk('../../input/til2020/val/val'):\n","    i = 0\n","    for filename in files:\n","        #if i == 1:\n","          #break\n","        img = '../../input/til2020/val/val/'+ filename\n","        image = read_image_bgr(img)\n","          \n","        # preprocess image for network\n","        image = preprocess_image(image)\n","        image, scale = resize_image(image)\n","\n","        # process image\n","        boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n","\n","        # correct for image scale\n","        boxes /= scale\n","        i+=1\n","        x = 0\n","        for box, score, label in zip(boxes[0], scores[0], labels[0]):\n","          #print(list(box))\n","          if x == 100:\n","            break\n","          elif float(score) < score_threshold:\n","            break\n","\n","          x +=1\n","          cat_id = int(label)\n","          conf = float(score)\n","          bbox = list(box)\n","          left = round(float(bbox[0]),1)\n","          top = round(float(bbox[1]),1)\n","          width = round(float(bbox[2] - bbox[0]),1)\n","          height = round(float(bbox[3] - bbox[1]),1)\n","          img_id = img.split(\"/\")[-1]\n","          img_id = int(img_id.split(\".\")[0])\n","\n","          detections.append( {'image_id':img_id, 'category_id':cat_id, 'bbox':[left, top, width, height], 'score':conf} )\n","    print(\"done\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"eJ3frKpZofOi","colab_type":"code","colab":{}},"source":["print(detections[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"QI-Kt7T9ofOk","colab_type":"code","colab":{}},"source":["detections2 = detections\n","for detection in detections2:\n","    if detection['category_id'] == 0:\n","        detection['category_id'] = 1\n","    elif detection['category_id'] == 1:\n","        detection['category_id'] = 2\n","    elif detection['category_id'] == 2:\n","        detection['category_id'] = 3\n","    elif detection['category_id'] == 3:\n","        detection['category_id'] = 4\n","    elif detection['category_id'] == 4:\n","        detection['category_id'] = 5\n","\n","print(detections2[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"ZUu_fHk_ofOm","colab_type":"code","colab":{}},"source":["import json\n","with open('./retina_combined15epochs.json', 'w') as f:\n","  json.dump(detections2, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"oc9br22gofOo","colab_type":"code","colab":{}},"source":["! python -m pip install numpy==1.17.1\n","! pip install git+https://github.com/jinmingteo/cocoapi.git#subdirectory=PythonAPI\n","\n","from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"KNyl55MuofOp","colab_type":"code","colab":{}},"source":["coco_gt = COCO('/kaggle/input/til2020/val.json')\n","coco_dt = coco_gt.loadRes('/kaggle/working/keras-retinanet/retina_combined15epochs.json')\n","cocoEval = COCOeval(cocoGt=coco_gt, cocoDt=coco_dt, iouType='bbox')\n","cocoEval.evaluate()\n","cocoEval.accumulate()\n","cocoEval.summarize()"],"execution_count":null,"outputs":[]}]}